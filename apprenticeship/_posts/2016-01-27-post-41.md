---
title: Alpha-beta pruning
comments: true
layout: apprenticeship-post
read-time: 3
category: apprenticeship
---

The biggest story in my iteration this week is to optimise the minimax algorithm for my Tic Tac Toe. I have to use the alpha-beta pruning technique to increase the speed with which the computer finds the next move.

<!--break-->

To begin with, I measured how long it currently takes. I wrote a test for this purpose in which I take the current time, then run the method that calculates the first computer move on an empty board 10 times, then I take the current time again. By subtracting the first time from the second time I can then see how long it took.

I ran this test 15 times and then took the average because each time was slightly different.

The goal is to improve the speed by 20% by using the alpha-beta pruning technique.

I read up on it yesterday on various computer sciencey websites. Every time I go on these websites, I’m so appalled by the styling. I don’t know why they all look so horrible! I think there’s a market for accessible and pleasing-to-the-eye websites that explain CS topics. If this whole apprenticeship thing doesn’t work out, I’ll go down that route and become rich through banner advertising on my pretty “CS Xplained" website that even people without 20/20 vision can read. (Don’t steal my idea).

But anyway, back to the alpha-beta pruning. After torturing my eyes with several of those websites, I ended up watching an MIT lecture on minimax and alpha-beta pruning and it was really good! The lecturer explained it really well and I feel like I get how it works.

I will try to explain. Imagine there is a game tree which at the end of each branch will create a game state and calculate the score for it. Let’s say there are only two levels of nodes. Here’s a screenshot of the friendly gentleman from MIT, who likes to pick on people in the front row, explaining how it works for a small game tree. He also explained it very well for a larger game tree but I decided that that was a bit much for this blog post.

![minimax lecture](/../../public/images/alpha-beta-mit.png "MIT lecture on minimax")


In the screenshot you can see that the first level is played by the maximising player and the second level by the minimising player.

The minimising player starts by looking at the score of the first branch, which needs to be calculated and turns out to be 2. So it knows that it can get a score as low as 2, but it has hope that it can minimise it even more, so it asks the next branch to calculate the score. Let's say that score is 7. 7 is greater than 2, so the minimising player doesn’t like that one and sticks with a score of 2 for its node in level 2.

The score of 2 gets pushed up to the maximising player in the first level and that player now knows that it can get at least a 2, if not a higher score. But let's see what the scores of the other branches are.

Back down to the minimising player. It asks the first branch of the second node to calculate its score. And that will be 1. So it knows that the score for the second node in level two will be 1 or less. That information gets pushed up to the maximising player who has already got 2 but ideally wants a higher number. In this case, it's not going to get it because the minimising player has 1 and tries to go even lower, if possible. 

![minimax lecture](/../../public/images/alpha-beta-mit2.png "MIT lecture on minimax")

So the maximising player will stick with 2 and the last score will not even be calculated anymore because it knows that the maximising player is never going to use it. 

And that's where the efficiency lies that makes the algorithm faster. With pure minimax, all game states are scored and evaluated and then the best scored move is chosen. But for alpha-beta pruning, it stops looking for other scores if it knows that it's not going to get a better one for the player that's a level higher up.

The theory sounds good! Now I just need to figure out how to implement it in code...